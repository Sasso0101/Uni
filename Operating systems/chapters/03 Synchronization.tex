\chapter{Process synchronization}

In modern operating systems processes can run concurrently. Although concurrency allows to achieve very high performance, it introduces some problems that need to be managed.

\section{Critical section}
The critical section problem happens when multiple processes are writing and reading from some shared data at the same time. The part of the code that modifies some shared data (updating common variables, writing to a file, updating tables...) is called \bold{critical section}.

A solution to the critical section problem must satisfy the following requirements:
\begin{enumerate}
    \item Mutual Exclusion: if process Pi is executing its critical section, then no other processes can be executing in their critical sections
    \item Progress: if no process is executing its critical section, then a process that want to execute its critical section should be able to do so
    \item Bounded waiting: a bound must exist on the number of times that other processes are allowed to enter their critical sections after a process has made a request to enter its critical section and before that request is granted (note that this does not imply anything on the time a process stays in its critical section)
\end{enumerate}

\bold{Liveness} refers to a set of properties that a system must satisfy to ensure processes make progress. Indefinite waiting is an example of a liveness failure.

\subsection{Peterson's solution}
The Peterson's solution applies to single-core processor and with $n$ processes. The processes share two variables: \code{int turn} and \code{boolean flag[n]}. The \code{turn} variable indicates whose turn it is to enter the critical section. The \code{flag} array is used to indicate if a process is ready to enter the critical section.

\snippet{code/03chapter/peterson.c}{c}{Implementation of Peterson's solution for process $i$ with two processes $i$ and $j$}

This solution satisfies the three CS requirements:
\begin{enumerate}
    \item Mutual exclusion is preserved (process $i$ enters CS only if: either flag[j] = false or turn = i)
    \item Progress requirement is satisfied
    \item Bounded-waiting requirement is met (because of alternating turns)
\end{enumerate}

Although Peterson's process is theoretically perfect, modern compilers and architectures perform various optimizations on the code. One of them is to change the order in which instructions are executed if they detect that it does not change the logic of the individual process. Therefore the \code{flag[i] = false} statement is not guaranteed to be executed exactly at the end of the critical section, thus breaking the synchronization mechanism.

This can be fixed by using memory barriers. When a memory barrier instruction is performed, the system ensures that all loads and stores of all processes are completed before any subsequent load or store operations are performed. Therefore we can add a memory barrier before setting the flag to false in the while loop.

\section{Hardware solutions}
Many systems provide hardware support for implementing the critical section code. Special hardware instructions that allow us to either test-and-modify the content of a word, or to swap the contents of two words atomically.

\subsection{Test and set instruction}
To access a critical section processes have to first call the \code{test_and_set()} instruction. This instruction must be non-interruptible (i.e. it has to be executed atomically).
\snippet{code/03chapter/test_and_set.c}{c}{Implementation of the \code{test_and_set()} function}
This solution satisfies mutual exclusion and progress, but it does not satisfy the bounded waiting requirement, because there is no mechanism that ensures that a process that requested access will enter the critical section.

\subsection{Compare and swap instruction}
The \code{compare_and_swap()} function must be executed atomically (for example it must be non-interruptible). When used with the lock it ensures that nobody else is reading or modifying the lock when it is executing.

To access a critical section processes have to first call the \code{compare_and_swap()} instruction on the lock and check if it is their turn. Then they will give the lock to the next process in line or release the lock. 
\snippet{code/03chapter/compare_and_swap.c}{c}{Implementation of the \code{compare_and_swap()} function}
This solution satisfies all requirements for the critical section.

The \code{lock} variable from the previous example is an example of an \bold{atomic variable}, i.e. a variable whose value changes atomically (non-interruptible).

\section{Software solutions}
Previous solutions are complicated and generally inaccessible to application programmers. In this section some software solutions will be shown, under the assumption that the programmer has access to some atomic functions.

\subsection{Mutex locks}
A simple solution for solving the critical section problem in software is using a mutex lock. A mutex lock is a boolean variable indicating if lock is available or not. When a process wants to access a critical section, it tries to acquire the lock and waits until it is able to do so using the \code{acquire()} atomic function. Then, it releases it when it is done executing using the \code{release()} atomic function. This solution requires busy waiting (this lock therefore called a spinlock), which is undesirable.

\subsection{Semaphore}
Semaphores are similar to semaphores, but can be also generalized to more than one process. Let \code{S} be an integer variable. When a process wants to enter its critical section, it calls the \code{wait(S)} atomic function, which will wait until the \code{S} variable is one. Then it will decrement it back to zero and let the process execute its critical section. After the process has finished executing its critical section it will call the \code{signal(S)} atomic function. This function will increment \code{S}, thus signalling to the next process that it can execute. This solution is also affected by the busy waiting problem.

\subsection{Semaphore without busy wait}
Semaphores can be used to solve the busy waiting problem. This can be done by making the variable \code{S} a queue of processes that wish to execute their critical section. Processes are added to the queue using the \code{block()} atomic function. Now the \code{wait()} function will just call the \code{block()} function, thus avoiding busy waiting. The next process in the queue is executed by calling the \code{wakeup()} function. Therefore the \code{signal()} function will call the \code{wakeup()} function.

\subsection{Monitors}
Monitors are structures that abstracts synchronization and exposes to the programmer a set of functions to access the data that the monitor holds. 
The monitor structure supports condition variables: these variables have a \code{x.wait()} method, which suspends the code of that process until the \code{x.signal()} method is called.

\image{images/Monitor.png}{12cm}{Monitor with condition variables}

Monitors can be implemented using semaphores and mutex.

\subsubsection{Resource allocator}
The resource allocator is an example of a monitor. Assume that a single resource has to be shared among multiple processes with different priorities. This can be implemented using a monitor structure implementing an \code{acquire()} and \code{release()} procedure. The \code{x.wait(c)} is a \italics{conditional-wait} function, where $c$ is the priority. When \code{x.signal()} is called, the process with the lowest priority number will be executed.
\snippet{code/03chapter/monitor.c}{c}{Monitor for resource allocator}

\section{Well-known synchronization problems}
In the literature there are some well known synchronization problems which have been solved already, namely the bounded buffer problem, the readers-writers problem and the dining philosophers problem.

\subsection{Bounded buffer problem}
A bounded buffer lets multiple producers and multiple consumers share a single buffer. Producers write data to the beginning of the buffer, while consumers read data from the end of the buffer. Producers must stop pushing data if the buffer is full, and consumers must stop if the buffer is empty.

\image{images/Bounded buffer.png}{12cm}{Bounded buffer with capacity $n$}
\snippet{code/03chapter/bounded_buffer.c}{c}{Solution for bounded buffer problem}

\subsection{Readers-writers problem}
A data set is shared among a number of concurrent processes: some processes are only readers, others can read and write. The problem to be solved is to allow multiple readers to read at the same time, but allowing only one writer to write at the same time.

\image{images/Readers writers.png}{12cm}{Readers-writers problem}

\snippet{code/03chapter/readers_writers.c}{c}{Solution for readers-writers problem}

\subsection{Dining philosophers}
N philosophers sit at a round table. Each has one chopstick on the left and one on the right and a bowl of rice. Each philosopher can only alternately think and eat. Occasionally they try to pick up two chopsticks (one at a time) to eat from the bowl (need both to eat, then release both when done). 

The problem is how to design a concurrent algorithm such that any philosopher will not starve; i.e., each can forever continue to alternate between eating and thinking.

Note that if each philosopher takes a chopstick at the same time, then they will wait indefinitely for the other one and no one will eat, thus creating a deadlock.

\image{images/Philosophers.png}{6cm}{Philosophers' problem}

% \begin{quote}
% A fool with a tool is still a fool.
% \end{quote}

\section{Deadlock}
Deadlock is a situation where two or more processes are waiting indefinitely for an event that can be caused by only one of the waiting processes.

A deadlock can happen if the following conditions hold:
\begin{itemize}
    \item Mutual exclusion: only one thread at a time can use the resource
    \item Hold and wait: a thread holding one resource is waiting to acquire additional resources held by other threads
    \item No preemption: a resource can be freed only voluntarily by the thread holding it
    \item Circular wait: in a set of threads $\{T_0, T_1, T_2, \dots , T_n\}$, thread $T_0$ is waiting for $T_1$, $T_1$ is waiting for $T_2$, $T_{n-1}$ is waiting for $T_n$ and $T_n$ is waiting for $T_0$
\end{itemize}

\subsection{Resource allocation graph}
Deadlocks can be represented using oriented graphs, called resource allocation graphs. Let the set of vertices $V$ be of two types:
\begin{itemize}
    \item $\{T_1, T_2, \dots, T_n\}$ the set of threads
    \item $\{R_1, R_2, \dots, R_n\}$ the set of resources
\end{itemize}
The request edges are denoted by $T_i \rightarrow R_j$ and the assignment edges are denoted by $R_j \rightarrow T_i$.

A deadlock happens if there are cycles in the graph and all resource instances of the cycles are inside a cycle.

\image{images/Deadlock.png}{4cm}{Resource allocation graph with deadlock}

\subsection{Deadlock prevention}
Deadlock can be prevented by avoiding one of the necessary conditions for deadlock.
\begin{itemize}
    \item Mutual exclusion: not feasible to not require it, must hold if there are non-sharable resources (such as when writing to files)
    \item Hold and wait: must guarantee that whenever a thread requests a resource, it does not hold any other resources. The cons of this solution are low resource utilization and possibility of Starvation
    \item No preemption
    \item Circular wait (solutions implemented in OSs): to avoid circular wait an order can be given to the resources. If a process wants to access two or more resources, it need to first obtain access to the resource with the lower index
\end{itemize}

\subsection{Deadlock avoidance}
Deadlock can be avoided if the system knows which resources threads want to access. Then they can execute an algorithm that detects possible deadlocks and prevents them before they happen. This technique is feasible in real-time operating systems, where tasks have to be allocated in advance for schedulability evaluation.

\section{Thread-safe states}
A state is safe if the system can allocate resources to the various processes in some particular order and avoid deadlock in doing so. An unsafe state is a state that may lead to deadlock. Not all unsafe states are actual deadlock.